{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mg_S12Hv91Et"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    "#from resnets_utils import *\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "from matplotlib.pyplot import imshow\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aYlxDwsEpWvK"
   },
   "outputs": [],
   "source": [
    "classes = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjeVvR62Nji5"
   },
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "arpsBNEbtLA9"
   },
   "outputs": [],
   "source": [
    "class identity_block(layers.Layer):\n",
    "  def __init__(self, filters, strides=1):\n",
    "    super(identity_block, self).__init__()\n",
    "    #self.conv1 = layers.Conv2D(filters, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform(seed=0))\n",
    "    self.conv1 = layers.Conv2D(filters, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform)\n",
    "    self.bn1 = layers.BatchNormalization(axis=3)\n",
    "    self.relu = layers.Activation('relu')\n",
    "    #self.conv2 = layers.Conv2D(filters, (3,3), strides=1, padding='same',kernel_initializer=random_uniform(seed=0))\n",
    "    self.conv2 = layers.Conv2D(filters, (3,3), strides=1, padding='same',kernel_initializer=random_uniform)\n",
    "    self.bn2 = layers.BatchNormalization(axis=3)\n",
    "    #self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform(seed=0))\n",
    "    self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform)\n",
    "    self.bn3 = layers.BatchNormalization(axis=3)\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    out = self.conv1(inputs)\n",
    "    out = self.bn1(out, training=training)\n",
    "    out = self.relu(out)\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out, training=training)\n",
    "    out = self.conv3(out)\n",
    "    out = self.bn3(out)\n",
    "    out = layers.add([out, inputs])\n",
    "    out = self.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "37auM-bao1em"
   },
   "outputs": [],
   "source": [
    "class convolutional_block(layers.Layer):\n",
    "  def __init__(self, filters, strides=1):\n",
    "    super(convolutional_block, self).__init__()\n",
    "    #self.conv1 = layers.Conv2D(filters, (1,1), strides=strides, padding='valid', kernel_initializer=glorot_uniform(seed=0))\n",
    "    self.conv1 = layers.Conv2D(filters, (1,1), strides=strides, padding='valid', kernel_initializer=glorot_uniform)\n",
    "    self.bn1 = layers.BatchNormalization(axis=3)\n",
    "    self.relu = layers.Activation('relu')\n",
    "    #self.conv2 = layers.Conv2D(filters, (3,3),strides=1 ,padding='same', kernel_initializer=glorot_uniform(seed=0))\n",
    "    self.conv2 = layers.Conv2D(filters, (3,3),strides=1 ,padding='same', kernel_initializer=glorot_uniform)  \n",
    "    self.bn2 = layers.BatchNormalization(axis=3)\n",
    "    #self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid', kernel_initializer=glorot_uniform)\n",
    "    self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid', kernel_initializer=glorot_uniform(seed=0))\n",
    "    self.bn3 = layers.BatchNormalization(axis=3)\n",
    "    self.downsample = tf.keras.Sequential()\n",
    "\n",
    "    #self.downsample.add(layers.Conv2D(filters*4, (1,1), strides=strides, kernel_initializer=glorot_uniform(seed=0)))\n",
    "    self.downsample.add(layers.Conv2D(filters*4, (1,1), strides=strides, kernel_initializer=glorot_uniform))\n",
    "    self.downsample.add(layers.BatchNormalization(axis=3))\n",
    "\n",
    "  def call(self, inputs, training = True):\n",
    "    out = self.conv1(inputs)\n",
    "    out = self.bn1(out, training = training)\n",
    "    out = self.relu(out)\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out, training = training)\n",
    "    out = self.relu(out)\n",
    "    out = self.conv3(out)\n",
    "    out = self.bn3(out, training = training)\n",
    "    shortcut = self.downsample(inputs, training = training)\n",
    "    #shortcut = layers.Conv2D(filters=out.shape[-1], kernel_size=(1,1), strides=1, padding='same', kernel_initializer=glorot_uniform(seed=0))(inputs)\n",
    "    #shortcut = BatchNormalization(axis=3)(shortcut, training = training)\n",
    "    out = layers.add([out, shortcut])\n",
    "    out = self.relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E5NgUiS2qQqf"
   },
   "outputs": [],
   "source": [
    "class ResNet50(Model):\n",
    "  def __init__(self,input_shape=(64,64,3)):\n",
    "    super(ResNet50,self).__init__()\n",
    "\n",
    "    self.conv_1 = tf.keras.Sequential([\n",
    "        ZeroPadding2D((3,3)),\n",
    "        #Conv2D(64, (7,7), strides=2, kernel_initializer=glorot_uniform(seed=0)),\n",
    "        Conv2D(64, (7,7), strides=2, kernel_initializer=glorot_uniform),\n",
    "        BatchNormalization(axis=3),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D((3,3), strides=2),\n",
    "    ])\n",
    "\n",
    "    self.block2 = tf.keras.Sequential([\n",
    "        #convolutional_block(f=3, filters=[64,64,256], s=1),\n",
    "        convolutional_block(filters=64),\n",
    "        identity_block(filters=64),\n",
    "        identity_block(filters=64)\n",
    "    ])\n",
    "\n",
    "    self.block3 = tf.keras.Sequential([\n",
    "        #convolutional_block(f=3, filters=[128,128,512],s=2),\n",
    "        convolutional_block(filters=128,strides=2),\n",
    "        identity_block(filters=128),\n",
    "        identity_block(filters=128),\n",
    "        identity_block(filters=128)\n",
    "    ])\n",
    "\n",
    "    self.block4 = tf.keras.Sequential([\n",
    "        #convolutional_block(f=3, filters=[256,256,1024],s=2),\n",
    "        convolutional_block(filters=256,strides=2),\n",
    "        identity_block(filters=256),\n",
    "        identity_block(filters=256),\n",
    "        identity_block(filters=256),\n",
    "        identity_block(filters=256),\n",
    "        identity_block(filters=256),\n",
    "    ])\n",
    "\n",
    "    self.block5 = tf.keras.Sequential([\n",
    "        #convolutional_block(f=3,filters=[512,512,2048],s=2),\n",
    "        convolutional_block(filters=512,strides=2),\n",
    "        identity_block(filters=512),\n",
    "        identity_block(filters=512),\n",
    "    ])\n",
    "\n",
    "    self.fc = tf.keras.Sequential([\n",
    "        AveragePooling2D(pool_size=(2,2)),\n",
    "        Flatten(),\n",
    "        #Dense(6, activation='softmax', kernel_initializer=glorot_uniform(seed=0))\n",
    "        Dense(6, activation='softmax', kernel_initializer=glorot_uniform)\n",
    "    ])\n",
    "  def call(self, inputs, training=False):\n",
    "    x = self.conv_1(inputs)\n",
    "    x = self.block2(x)\n",
    "    x = self.block3(x)\n",
    "    x = self.block4(x)\n",
    "    x = self.block5(x)\n",
    "    return self.fc(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50jpMyMiNpfH"
   },
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fb0QSw1qrW11"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('./datasets/Files/train_signs.h5', \"r\")\n",
    "    \n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "    train_set_y_orig = np.array(\n",
    "        train_dataset[\"train_set_y\"][:])  \n",
    "\n",
    "    test_dataset = h5py.File('./datasets/Files/test_signs.h5', \"r\")\n",
    "    \n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "    test_set_y_orig = np.array(\n",
    "        test_dataset[\"test_set_y\"][:])  \n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])  \n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r4UAIBt7L020"
   },
   "outputs": [],
   "source": [
    "X_train_orig, y_train_orig, X_test_orig, y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1080)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape = y_train_orig.reshape((y_train_orig.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 2, ..., 2, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YM46GP0mL41i",
    "outputId": "4df19650-a6fc-45ce-9ddd-495d1832f6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (1, 1080, 6)\n",
      "y_test shape: (1, 120, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig / 255.\n",
    "X_test = X_test_orig /255.\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train_orig, num_classes=len(classes))\n",
    "y_test = tf.keras.utils.to_categorical(y_test_orig, num_classes=len(classes))\n",
    "\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGVoxEornIEc",
    "outputId": "535ecd28-91f5-4b67-a2b7-73c9b7613918"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sCN-gKGxL7uq"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape((y_train.shape[1], y_train.shape[2]))\n",
    "y_test = y_test.reshape((y_test.shape[1], y_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H5DcoSYx4Dzn",
    "outputId": "3b4757ab-6909-4e9b-8709-495af116f302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1080, 64, 64, 3)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "y_train shape: (1080, 6)\n",
      "y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_test shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrK6Q897Ntod"
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rCDWMZUFL_3N"
   },
   "outputs": [],
   "source": [
    "keras.backend.set_learning_phase(True)\n",
    "model = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "H32EgElDlXRe"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HrgRDjWHlhpz",
    "outputId": "23291763-6c4a-4796-ad77-fb1de6ba636f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\huyho\\anaconda3\\envs\\python-jupyter\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 3s/step - accuracy: 0.4237 - loss: 2.1965\n",
      "Epoch 2/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3s/step - accuracy: 0.8008 - loss: 0.5267\n",
      "Epoch 3/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.8995 - loss: 0.3149\n",
      "Epoch 4/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.9018 - loss: 0.2763\n",
      "Epoch 5/5\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 3s/step - accuracy: 0.9649 - loss: 0.1338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17d65ecf4d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_reshape, epochs=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67OSZ9UwM3FZ",
    "outputId": "18d84e22-be67-4d0e-e688-c5102f978a57"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras._tf_keras.keras.backend' has no attribute 'set_learning_phase'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mset_learning_phase(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(X_train, y_train_reshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.backend' has no attribute 'set_learning_phase'"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.set_learning_phase(False)\n",
    "model.evaluate(X_train, y_train_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNAchPvSE7yg"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
