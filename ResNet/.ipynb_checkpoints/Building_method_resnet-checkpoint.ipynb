{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D,Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, BatchNormalization\n",
        "#from resnets_utils import *\n",
        "from tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "from matplotlib.pyplot import imshow\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import *"
      ],
      "metadata": {
        "id": "Mg_S12Hv91Et"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = 6"
      ],
      "metadata": {
        "id": "aYlxDwsEpWvK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Model"
      ],
      "metadata": {
        "id": "vjeVvR62Nji5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class identity_block(layers.Layer):\n",
        "  def __init__(self, filters, strides=1):\n",
        "    super(identity_block, self).__init__()\n",
        "    self.conv1 = layers.Conv2D(filters, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform(seed=0))\n",
        "    self.bn1 = layers.BatchNormalization(axis=3)\n",
        "    self.relu = layers.Activation('relu')\n",
        "    self.conv2 = layers.Conv2D(filters, (3,3), strides=1, padding='same',kernel_initializer=random_uniform(seed=0))\n",
        "    self.bn2 = layers.BatchNormalization(axis=3)\n",
        "    self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid',kernel_initializer=random_uniform(seed=0))\n",
        "    self.bn3 = layers.BatchNormalization(axis=3)\n",
        "\n",
        "  def call(self, inputs, training=None):\n",
        "    out = self.conv1(inputs)\n",
        "    out = self.bn1(out, training=training)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out, training=training)\n",
        "    out = self.conv3(out)\n",
        "    out = self.bn3(out)\n",
        "    out = layers.add([out, inputs])\n",
        "    out = self.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "arpsBNEbtLA9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class convolutional_block(layers.Layer):\n",
        "  def __init__(self, filters, strides=1):\n",
        "    super(convolutional_block, self).__init__()\n",
        "    self.conv1 = layers.Conv2D(filters, (1,1), strides=strides, padding='valid', kernel_initializer=glorot_uniform(seed=0))\n",
        "    self.bn1 = layers.BatchNormalization(axis=3)\n",
        "    self.relu = layers.Activation('relu')\n",
        "    self.conv2 = layers.Conv2D(filters, (3,3),strides=1 ,padding='same', kernel_initializer=glorot_uniform(seed=0))\n",
        "    self.bn2 = layers.BatchNormalization(axis=3)\n",
        "    self.conv3 = layers.Conv2D(filters*4, (1,1), strides=1, padding='valid', kernel_initializer=glorot_uniform(seed=0))\n",
        "    self.bn3 = layers.BatchNormalization(axis=3)\n",
        "    self.downsample = tf.keras.Sequential()\n",
        "\n",
        "    self.downsample.add(layers.Conv2D(filters*4, (1,1), strides=strides, kernel_initializer=glorot_uniform(seed=0)))\n",
        "    self.downsample.add(layers.BatchNormalization(axis=3))\n",
        "\n",
        "  def call(self, inputs, training = None):\n",
        "    out = self.conv1(inputs)\n",
        "    out = self.bn1(out, training = training)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out, training = training)\n",
        "    out = self.relu(out)\n",
        "    out = self.conv3(out)\n",
        "    out = self.bn3(out, training = training)\n",
        "    shortcut = self.downsample(inputs, training = training)\n",
        "    #shortcut = layers.Conv2D(filters=out.shape[-1], kernel_size=(1,1), strides=1, padding='same', kernel_initializer=glorot_uniform(seed=0))(inputs)\n",
        "    #shortcut = BatchNormalization(axis=3)(shortcut, training = training)\n",
        "    out = layers.add([out, shortcut])\n",
        "    out = self.relu(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "37auM-bao1em"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E5NgUiS2qQqf"
      },
      "outputs": [],
      "source": [
        "class ResNet50(Model):\n",
        "  def __init__(self,input_shape=(64,64,3)):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv_1 = tf.keras.Sequential([\n",
        "        ZeroPadding2D((3,3)),\n",
        "        Conv2D(64, (7,7), strides=2, kernel_initializer=glorot_uniform(seed=0)),\n",
        "        BatchNormalization(axis=3),\n",
        "        Activation('relu'),\n",
        "        MaxPooling2D((3,3), strides=2),\n",
        "    ])\n",
        "\n",
        "    self.block2 = tf.keras.Sequential([\n",
        "        #convolutional_block(f=3, filters=[64,64,256], s=1),\n",
        "        convolutional_block(filters=64),\n",
        "        identity_block(filters=64),\n",
        "        identity_block(filters=64)\n",
        "    ])\n",
        "\n",
        "    self.block3 = tf.keras.Sequential([\n",
        "        #convolutional_block(f=3, filters=[128,128,512],s=2),\n",
        "        convolutional_block(filters=128,strides=2),\n",
        "        identity_block(filters=128),\n",
        "        identity_block(filters=128),\n",
        "        identity_block(filters=128)\n",
        "    ])\n",
        "\n",
        "    self.block4 = tf.keras.Sequential([\n",
        "        #convolutional_block(f=3, filters=[256,256,1024],s=2),\n",
        "        convolutional_block(filters=256,strides=2),\n",
        "        identity_block(filters=256),\n",
        "        identity_block(filters=256),\n",
        "        identity_block(filters=256),\n",
        "        identity_block(filters=256),\n",
        "        identity_block(filters=256),\n",
        "    ])\n",
        "\n",
        "    self.block5 = tf.keras.Sequential([\n",
        "        #convolutional_block(f=3,filters=[512,512,2048],s=2),\n",
        "        convolutional_block(filters=512,strides=2),\n",
        "        identity_block(filters=512),\n",
        "        identity_block(filters=512),\n",
        "    ])\n",
        "\n",
        "    self.fc = tf.keras.Sequential([\n",
        "        AveragePooling2D(pool_size=(2,2)),\n",
        "        Flatten(),\n",
        "        Dense(6, activation='softmax', kernel_initializer=glorot_uniform(seed=0)),\n",
        "    ])\n",
        "  def call(self, inputs, training=False):\n",
        "    x = self.conv_1(inputs)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    x = self.block4(x)\n",
        "    x = self.block5(x)\n",
        "    return self.fc(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "50jpMyMiNpfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "def load_dataset():\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/Colab Notebooks/train_signs.h5', \"r\")\n",
        "    # your train set features\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "    train_set_y_orig = np.array(\n",
        "        train_dataset[\"train_set_y\"][:])  # your train set labels\n",
        "\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/Colab Notebooks/test_signs.h5', \"r\")\n",
        "    # your test set features\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "    test_set_y_orig = np.array(\n",
        "        test_dataset[\"test_set_y\"][:])  # your test set labels\n",
        "\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "metadata": {
        "id": "Fb0QSw1qrW11"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_orig, y_train_orig, X_test_orig, y_test_orig, classes = load_dataset()"
      ],
      "metadata": {
        "id": "r4UAIBt7L020"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_orig / 255.\n",
        "X_test = X_test_orig /255.\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train_orig, num_classes=len(classes))\n",
        "y_test = tf.keras.utils.to_categorical(y_test_orig, num_classes=len(classes))\n",
        "\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM46GP0mL41i",
        "outputId": "4df19650-a6fc-45ce-9ddd-495d1832f6c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train shape: (1, 1080, 6)\n",
            "y_test shape: (1, 120, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGVoxEornIEc",
        "outputId": "535ecd28-91f5-4b67-a2b7-73c9b7613918"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1080, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.reshape((y_train.shape[1], y_train.shape[2]))\n",
        "y_test = y_test.reshape((y_test.shape[1], y_test.shape[2]))"
      ],
      "metadata": {
        "id": "sCN-gKGxL7uq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'X_train shape: {X_train.shape}')\n",
        "print(f'X_test shape: {X_test.shape}')\n",
        "print(f'y_train shape: {y_train.shape}')\n",
        "print(f'y_test shape: {y_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5DcoSYx4Dzn",
        "outputId": "3b4757ab-6909-4e9b-8709-495af116f302"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1080, 64, 64, 3)\n",
            "X_test shape: (120, 64, 64, 3)\n",
            "y_train shape: (1080, 6)\n",
            "y_test shape: (120, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "TrK6Q897Ntod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()"
      ],
      "metadata": {
        "id": "rCDWMZUFL_3N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "H32EgElDlXRe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=1,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrgRDjWHlhpz",
        "outputId": "23291763-6c4a-4796-ad77-fb1de6ba636f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5575: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 191s 5s/step - loss: 1.7388 - accuracy: 0.5370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x797ab61b3280>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67OSZ9UwM3FZ",
        "outputId": "18d84e22-be67-4d0e-e688-c5102f978a57"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 17s 475ms/step - loss: 329.7787 - accuracy: 0.1667\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[329.7786865234375, 0.1666666716337204]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "RNAchPvSE7yg"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}